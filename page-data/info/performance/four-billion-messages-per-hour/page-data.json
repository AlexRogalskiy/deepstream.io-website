{"componentChunkName":"component---src-templates-info-tsx","path":"/info/performance/four-billion-messages-per-hour/","webpackCompilationHash":"0f3352f8274dbe1392d8","result":{"data":{"markdownRemark":{"html":"<p>When it comes to benchmarking realtime systems, there are three core metrics to watch out for:</p>\n<p><strong>Latency:</strong> the speed at which updates traverse the system</p>\n<p><strong>Concurrency:</strong> the number of simultaneous clients</p>\n<p><strong>Throughput:</strong> How many updates can be sent to clients in a given time</p>\n<p>We’ve concentrated on latency and to some extent concurrency in <a href=\"/info/performance/single-node-vs-cluster/\">the last set of benchmarks</a>, but now it’s time to look into throughput.</p>\n<h2 id=\"a-real-world-test\"><a href=\"#a-real-world-test\" aria-label=\"a real world test permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>A real world test</h2>\n<p>It’s important to stress that our benchmarking approach aims to identify the best possible performance for real-world messages and cost-efficient infrastructure setups. It is perfectly possible to increase the achieved test results by up to 400% by reducing messages to single character events and reserving dedicated, network optimized bare metal instances, but the use of these metrics would be of very debatable value.</p>\n<h3 id=\"test-setup\"><a href=\"#test-setup\" aria-label=\"test setup permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Test Setup</h3>\n<p>We ran two suites of tests, one for a single deepstream node, one for a cluster of six nodes. In both scenarios, a single provider pumped simulated foreign exchange rate updates into deepstream which were distributed across a number of connected test-clients.</p>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/059199da0d86bad768ebc08f5dddcad5/fa92b/cluster.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 840px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 42.21428571428571%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAyElEQVQoz3VQWw7DIAzj/jfdpn1stEB4eTFtKlSxSFGc1HZIHc6oreP5jai1QnIZuLWGKBmPTwB6w54ELx9PnC/81rpLHT6u9w5mVpPvtqOUAlETYponkQvHlAZu7cB+Dzov2LSyp48TFTBzzhAdEietKcUxs+SiAx9c47CajkuvF1rwTBOTHGNE0LRFIYQxY08eTWa9M3A3tpkt8H5TQxn9nTfrrxeucg4pFW2a/dO41ab7i1l5Js9bfVuevIqZzH/Kc+elq/gBNT13fKCBe64AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Test Setup\"\n        title=\"\"\n        src=\"/static/059199da0d86bad768ebc08f5dddcad5/04a72/cluster.png\"\n        srcset=\"/static/059199da0d86bad768ebc08f5dddcad5/6a467/cluster.png 210w,\n/static/059199da0d86bad768ebc08f5dddcad5/635b1/cluster.png 420w,\n/static/059199da0d86bad768ebc08f5dddcad5/04a72/cluster.png 840w,\n/static/059199da0d86bad768ebc08f5dddcad5/c6d2c/cluster.png 1260w,\n/static/059199da0d86bad768ebc08f5dddcad5/fa92b/cluster.png 1400w\"\n        sizes=\"(max-width: 840px) 100vw, 840px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>We’ve open-sourced all aspects of our test-framework. If you’d like to run the tests yourself or benchmark your custom setup, please find them <a href=\"https://github.com/deepstreamIO/ds-test-fx\">here</a></p>\n<h3 id=\"test-clients\"><a href=\"#test-clients\" aria-label=\"test clients permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Test Clients</h3>\n<p>We’ve developed a remote-controllable “probe” that can be used as both client and data-provider. Each probe is an independent process within a docker container that connects to a control deepstream-server upon startup and waits for further instructions.</p>\n<p>Whenever a probe comes online, its presence is reported to a browser based dashboard using deepstream’s <a href=\"/tutorials/core/active-data-providers/\">listen</a> feature.\nFrom this dashboard it is possible to configure each probe, set its role as a client or a provider, its update frequency and subscriptions and connect it to any given deepstream node.</p>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4374a73ad1dd3d23c54967845acc2fcb/02da8/dashboard.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 840px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 50.10504201680672%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABiUlEQVQoz22S13LrMBBD/f/faMdFLlEhKfbYSgYXoKU83MnDDqHlFhxJOz9NmIcBNQSkeYajfqYI7wLGySOXBSnkVvNKCa+cYfu+PS/UxfsWytdasfv6/MSLBeV2w1sPKNcO5jGjH77RdQn27vA99EjXK8r9joXDVK9Qb2WuPh4oXLizHx/wunQO7nTC3HUo1uDRGRzPEZMpmG4jHOsiaRIHSAeeeRzR+jWM/SVG7PzlgsDNlZeBwxSFbtxtQH8ZMfeWDTzPJyQSFIY/nxHlik6lAw2pvzn8RWZB08KR5taf8Y0mvahhRVuGkee9oape9+ptA83hAEeHWcjHIxw3JktXdG75HI1BYKPZ7xGIHLncHvbwPBOXKD/z/hdZiFEvmwU6FZnbEp1F3iVuz4zABdJCVj4Kkz1bv/CbQyHIdmXh/1qYOuv6KoS16a3myaHKP7eBE5EttwhZiJZfOq7IRl9zRZ6EPL6RG6Yo+AqUd3SbN2ShKYSV2dhQ9Rvp+S/NQU0Lc9VpzcvhP/cm8JgAPbwSAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Dashboard\"\n        title=\"\"\n        src=\"/static/4374a73ad1dd3d23c54967845acc2fcb/04a72/dashboard.png\"\n        srcset=\"/static/4374a73ad1dd3d23c54967845acc2fcb/6a467/dashboard.png 210w,\n/static/4374a73ad1dd3d23c54967845acc2fcb/635b1/dashboard.png 420w,\n/static/4374a73ad1dd3d23c54967845acc2fcb/04a72/dashboard.png 840w,\n/static/4374a73ad1dd3d23c54967845acc2fcb/c6d2c/dashboard.png 1260w,\n/static/4374a73ad1dd3d23c54967845acc2fcb/27aa4/dashboard.png 1680w,\n/static/4374a73ad1dd3d23c54967845acc2fcb/02da8/dashboard.png 1904w\"\n        sizes=\"(max-width: 840px) 100vw, 840px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>High level metrics from the probe, e.g. messages received or send in the last second are streamed to the dashboard and aggregated there. Lower level system metrics like CPU usage or memory consumption are aggregated on the individual machines using the <code class=\"language-text\">top</code> linux process manager and collected at the end of the tests.</p>\n<h3 id=\"server-machines\"><a href=\"#server-machines\" aria-label=\"server machines permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Server Machines</h3>\n<p>Our tests were run on Amazon Web Services infrastructure.\ndeepstream nodes are single-threaded processes with non-blocking I/O that scale via clustering. This makes it is possible to utilize multi-core CPUs by running multiple deepstream nodes on the same machine - but with the downside that nodes are subject to the limitations of that machine (ephemeral port limits, thread and memory allocation, single point of failure if the machine goes down etc.).</p>\n<p>We therefore went with the recommended approach of spreading deepstream servers across multiple smaller machines, leading to higher fault tolerance, better resource utilisation and horizontal scalability. After extensive evaluation we found that EC2 t2.medium instances provide the best performance-to-cost ratio and used this instance type to host the servers in our test.</p>\n<h3 id=\"messages\"><a href=\"#messages\" aria-label=\"messages permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Messages</h3>\n<p>To allow for realistic message sizes, we’ve used simulated foreign exchange price update events as messages. Each event had a name such as fx/gbpusd (foreign exchange rate for pound against dollar) and transmitted a single floating point number with a five digit precision, e.g. 1.34325. This results in an average message size of ~23bytes.\nThe number is changed for every update and events are distributed over hundreds of different topics.</p>\n<h2 id=\"results---single-node\"><a href=\"#results---single-node\" aria-label=\"results   single node permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Results - Single Node</h2>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/82973853cbc31761c798e9eb589d0e47/e6592/single-node.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 695px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 78.9928057553957%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABEUlEQVQ4y6VU2Y7DIAzk//9un/oF1b5tkcJ9xPXQJGto0/SIFNnYZhgzgKKDb57nzaaUuvGjT70KWGsl530H+Aj0EJCn/oOUchsv8bcYjq0Z5+n0q8nG0jEcWSqZGIukX3Kmn7Omi0t3OQmq9jZXxuFnBpymiSq3PeYkuBqDMgkhCgNA3RhjAw0hsE0tPpLBuDHEytZacs6RNaZZgBn2Ed9ywjdLHRaR6isYBD0HsXqzzAYMwAo/4rAr03UclzrEQaBrGauhEAxgZRtr63ut3rW8l+xUZiDrw8Zkb9+fiiJ9bMuf5XZzeX5sXrl6t/qZQspUv7nLkkUTgwWDAB/fZTkJYmmt2yn46nGQ+wT1j56vKzHd88wBj15EAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Single node\"\n        title=\"\"\n        src=\"/static/82973853cbc31761c798e9eb589d0e47/e6592/single-node.png\"\n        srcset=\"/static/82973853cbc31761c798e9eb589d0e47/6a467/single-node.png 210w,\n/static/82973853cbc31761c798e9eb589d0e47/635b1/single-node.png 420w,\n/static/82973853cbc31761c798e9eb589d0e47/e6592/single-node.png 695w\"\n        sizes=\"(max-width: 695px) 100vw, 695px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>Time to start exploring the limits of a single node, starting with CPU consumption. We’ve clocked the maximum throughput of an individual deepstream at 400,000 events per second on a c4.2xlarge high CPU machine. That’s good to know, but collides with our best value for money performance testing policy. On c4.2xlarge, sending a billion messages cost 36 cents.</p>\n<p>Moving towards a way more affordable t2.medium instance, we found a sweet spot for CPU utilisation between 160k and 200k messages per second.</p>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/f9cba99baeb2e214d3bceffb2e7732d5/c07e5/cpu-single-node.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 840px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 55.81140350877193%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABfklEQVQoz5VT127DMAz0//9fA7RpAyTNXrYly9q6knTsDOSlAgiSknk8HeUKt5VzglKKrEXXdTCmg2rbIdea9rTkdV3Ldy3FmvbZYoyCUUpBFUJApsC4SKBATAUuZLIkZv3gfcwIZGNhzkX8q1WlZDlsTMDPrsVFOTqAgIbIjZIAcW59xrv1BJhSEkBmsTy0mK3O+Fxfcag7rM8Kp9ZQo5py8tsGq6PC70lhsW9wbAw81RHkHZC140D3AYnuXHdOQJdUyMAM8LE8Y7FrMN/W+Cb72lwx3wz+1Pa3GTwwTJQYG9CR/Xf1Ljxdu8ppEJ4ZMigLmBLrmoXx6NlYljHmQboQJxITQ76/JcGv2k30302PjYczxrw4N/aVIWnIk9yT6OuzvnW7Fz7GPAABE0BuwLWjTMNe5Yn2obGYLS8yvZE+Aw0f4caoTG8xkiQoA+BVW/Ser+5Fqso6Jy9dBtPb6dV77yh3sNbKn2OdR0/nSmk6G1g5T3sExE20sQhE7g+i5VwqfaKy9gAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"CPU single node\"\n        title=\"\"\n        src=\"/static/f9cba99baeb2e214d3bceffb2e7732d5/04a72/cpu-single-node.png\"\n        srcset=\"/static/f9cba99baeb2e214d3bceffb2e7732d5/6a467/cpu-single-node.png 210w,\n/static/f9cba99baeb2e214d3bceffb2e7732d5/635b1/cpu-single-node.png 420w,\n/static/f9cba99baeb2e214d3bceffb2e7732d5/04a72/cpu-single-node.png 840w,\n/static/f9cba99baeb2e214d3bceffb2e7732d5/c07e5/cpu-single-node.png 912w\"\n        sizes=\"(max-width: 840px) 100vw, 840px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>At 10 cents per billion messages this means that we can get almost twice the performance out of a cluster of t2.medium instances than we would from c4.2xlarge.</p>\n<p>But what about memory? Fortunately that isn’t too much of a concern. deepstream is a stateless, transactional server that - when connected to an external cache - doesn’t hold data itself… memory tends to level around 80MB per node and is freed up for garbage collection almost immediately after messages are processed.</p>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/147814fc6d2214a0efc3e1a148ec5de9/c0c7b/memory-single-node.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 840px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 55.84699453551912%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABEElEQVQoz6VSCY7DIAzM/7+6RyABjLlmbVO62arSXkiWp+54PIZsuJ0QI5zz8N7jOA7L53li390da3bOWSg2rtSj9OoZY2ArpRj471ENE+y9W4G4gUtD4iq4IuaZk+QsdbrVrSah3BWltmlKBVtraCKqTW8HWfjIlveQ8X4SjsRwgle8eMIptUCMSMVquVQzZg57HyI67E8Z8+16rfUv18R1bmCCVX6oOxfYpipRB1iMh+jznlRAt1qiKRdxW6Zg5oJXWUFXW6TfRhXHurbe5fb4wn8RvPbao4zbSs/I/eK6/2ADE1zE+UATr0GfrvsdP+MvvDEzap0vpFg/9IUjZaRECCGAMoNo4itn9WpNTXwAPwBjDUCSUb0AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Memory single node\"\n        title=\"\"\n        src=\"/static/147814fc6d2214a0efc3e1a148ec5de9/04a72/memory-single-node.png\"\n        srcset=\"/static/147814fc6d2214a0efc3e1a148ec5de9/6a467/memory-single-node.png 210w,\n/static/147814fc6d2214a0efc3e1a148ec5de9/635b1/memory-single-node.png 420w,\n/static/147814fc6d2214a0efc3e1a148ec5de9/04a72/memory-single-node.png 840w,\n/static/147814fc6d2214a0efc3e1a148ec5de9/c0c7b/memory-single-node.png 915w\"\n        sizes=\"(max-width: 840px) 100vw, 840px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>However, there’s one thing to be aware of: deepstream relies on garbage collection to free up dereferenced memory. If a machine’s CPU is overutilized above 100% for a consecutive time, garbage collection will be delayed and memory can add up. If this continues for a prolonged period, the server will run out of memory and eventually crash - so be generous enough when it comes to resource allocation to make sure that your processors get some breathing space every once in a while.</p>\n<h2 id=\"results---cluster\"><a href=\"#results---cluster\" aria-label=\"results   cluster permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Results - Cluster</h2>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/059199da0d86bad768ebc08f5dddcad5/fa92b/cluster.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 840px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 42.21428571428571%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAyElEQVQoz3VQWw7DIAzj/jfdpn1stEB4eTFtKlSxSFGc1HZIHc6oreP5jai1QnIZuLWGKBmPTwB6w54ELx9PnC/81rpLHT6u9w5mVpPvtqOUAlETYponkQvHlAZu7cB+Dzov2LSyp48TFTBzzhAdEietKcUxs+SiAx9c47CajkuvF1rwTBOTHGNE0LRFIYQxY08eTWa9M3A3tpkt8H5TQxn9nTfrrxeucg4pFW2a/dO41ab7i1l5Js9bfVuevIqZzH/Kc+elq/gBNT13fKCBe64AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Cluster\"\n        title=\"\"\n        src=\"/static/059199da0d86bad768ebc08f5dddcad5/04a72/cluster.png\"\n        srcset=\"/static/059199da0d86bad768ebc08f5dddcad5/6a467/cluster.png 210w,\n/static/059199da0d86bad768ebc08f5dddcad5/635b1/cluster.png 420w,\n/static/059199da0d86bad768ebc08f5dddcad5/04a72/cluster.png 840w,\n/static/059199da0d86bad768ebc08f5dddcad5/c6d2c/cluster.png 1260w,\n/static/059199da0d86bad768ebc08f5dddcad5/fa92b/cluster.png 1400w\"\n        sizes=\"(max-width: 840px) 100vw, 840px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    \nArmed with these results, we’ve started looking at subjecting a cluster of six nodes, connected by an AWS Elasticache Redis message bus to a performance test. The goal here was simple - gradually increase the throughput to one million messages per second, then leave the cluster running for a continuous amount of time to monitor CPU and memory usage.</p>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/bfd996542b4b37c380e5906c1418f46a/8e846/cpu-cluster.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 840px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 43.06666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsSAAALEgHS3X78AAABJElEQVQoz5VQYU+DMBDt//8JfpzRf6CLbsk2jfphCmYqGXOAY40bDBhCKbS9dhYiy/SL+vJyvXfNa+8OKaV2h2gkJTkr6WGNCwmgBEiQSlNogkJ7c8mlu6EP3vYZZ6YTTPx0uiIvOLuebm7s6HYW382ioRX2ntYjKxhZoR+VtVk2fsONjy6mJyOnM3jtDObHw7mOp1du18Dn48XZ2Os/4u69f2kseybum3iVECSl1G3pTiZesggyP8yd99TGycQN7WUcppRWsE4KffVRMFKKioMeQUcGEjHGAISuvgWkHfmvQFlR6c7nKxJlTGupZ2jQnvVOGtbPtvnXHyinbEuYjTNSlN+3rn7NUUpYkFaUiZ2Su38C5UVZMQ6Ccy4Osde8xQ8JAJ8vaAH9qju/AgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"CPU results in a cluster\"\n        title=\"\"\n        src=\"/static/bfd996542b4b37c380e5906c1418f46a/04a72/cpu-cluster.png\"\n        srcset=\"/static/bfd996542b4b37c380e5906c1418f46a/6a467/cpu-cluster.png 210w,\n/static/bfd996542b4b37c380e5906c1418f46a/635b1/cpu-cluster.png 420w,\n/static/bfd996542b4b37c380e5906c1418f46a/04a72/cpu-cluster.png 840w,\n/static/bfd996542b4b37c380e5906c1418f46a/c6d2c/cpu-cluster.png 1260w,\n/static/bfd996542b4b37c380e5906c1418f46a/8e846/cpu-cluster.png 1500w\"\n        sizes=\"(max-width: 840px) 100vw, 840px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<p>At one million messages per second, average CPU utilisation was at 80%. The node that received the data-input and forwarded it to both the message bus and its connected clients was predictably under higher load with occasional spikes towards the higher 90% range. Memory stayed stable below 80MB with garbage collection leading to volatile spikes during cleanup.</p>\n<p>\n  <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/263468c9ebfd023fa272e6d493a370e1/8e846/memory-cluster.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n  \n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 840px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 43.06666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAAsSAAALEgHS3X78AAAA/UlEQVQoz52P226DMAyG8/4Pt4tN7SaqdmWUtoBCQs5xDsylUobGrvZdJL9/O7ZDUko5Z2U9FZYrzzUwBcNk60F23PaTQ91z03PbMXOhGkMmXTNI4wOZ59lBPN2nqmWv53Hf8JcjfavH3dd4uIn3hlXXad+wjws/3cVnJ6uWo7Nr+KSB4FhsTIXXLhxv4tzLQzvVg2LKKxuwLwppQbmgLAgTRumocNcRByfClWupCcv2+F4YENobH1Oa0cG9MIHi8becQ8zWB+1AGkCfQAhYsqQepYVnWM51tmiyLSrMG4r/vElK+X/8TN72/rXhnxAA/HWAhbBi7RQdYywh6m+r3wwGa03/hAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"Memory in a cluster\"\n        title=\"\"\n        src=\"/static/263468c9ebfd023fa272e6d493a370e1/04a72/memory-cluster.png\"\n        srcset=\"/static/263468c9ebfd023fa272e6d493a370e1/6a467/memory-cluster.png 210w,\n/static/263468c9ebfd023fa272e6d493a370e1/635b1/memory-cluster.png 420w,\n/static/263468c9ebfd023fa272e6d493a370e1/04a72/memory-cluster.png 840w,\n/static/263468c9ebfd023fa272e6d493a370e1/c6d2c/memory-cluster.png 1260w,\n/static/263468c9ebfd023fa272e6d493a370e1/8e846/memory-cluster.png 1500w\"\n        sizes=\"(max-width: 840px) 100vw, 840px\"\n      />\n    </span>\n  </span>\n  \n  </a>\n    </p>\n<h2 id=\"conclusion\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>After running variations of this test for up to an hour we can conclude:</p>\n<ul>\n<li>A cluster of six nodes caters reliably for  <strong>~four billion messages an hour</strong>.</li>\n<li>Clusters scale linearly - larger throughput rates can easily be achieved by adding additional nodes</li>\n<li>The costs of running a six-instance cluster for an hour on AWS are 36 cents (6 x t2.medium @ 0.052$/h + 1 x cache.t2.medium @ 0.068$/h)</li>\n</ul>","frontmatter":{"title":"Four billion messages an hour - benchmarking deepstream throughput"},"fields":{"slug":"/info/performance/four-billion-messages-per-hour/","githubLink":"https://github.com/deepstreamIO/deepstream.io-website/blob/master/content/info/performance/four-billion-messages-per-hour/index.md"}}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/info/performance/four-billion-messages-per-hour/","navigation":{"order":100,"community":{"order":100,"contribution-guidelines":{"slug":"/info/community/contribution-guidelines/","title":"Open Source Contribution Guidelines","description":"Find out how you can contribute to deepstream","leaf":true,"order":100,"":{"order":100}},"get-in-touch":{"slug":"/info/community/get-in-touch/","title":"Getting in touch","description":"Find out how to get in touch with other deepstream aficionados","leaf":true,"order":100,"":{"order":100}}},"performance":{"order":100,"four-billion-messages-per-hour":{"slug":"/info/performance/four-billion-messages-per-hour/","title":"Four billion messages an hour - benchmarking deepstream throughput","description":"A report on deepstream throughput performance testing","leaf":true,"order":100,"":{"order":100}},"overview":{"slug":"/info/performance/overview/","title":"Performance Overview","description":"An overview on deepstream performance and running your tests","leaf":true,"order":100,"":{"order":100}},"single-node-vs-cluster":{"slug":"/info/performance/single-node-vs-cluster/","title":"Latency tests","description":"A suite of tests to determine message latency under load","leaf":true,"order":100,"":{"order":100}}}}}}}